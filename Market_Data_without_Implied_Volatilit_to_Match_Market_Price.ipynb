{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huang\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import svm\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DWDP','XOM',\n",
    "             'GE','GS','HD','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT',\n",
    "             'NKE','PFE','PG','TRV','UNH','UTX','VZ','V','WMT','DIS']\n",
    "\n",
    "df = None\n",
    "for company in companies:\n",
    "    temp_df = pd.read_excel('data\\{}.xlsx'.format(company,na_value='nan'))\n",
    "    if df is None:\n",
    "        df = temp_df\n",
    "    else:\n",
    "        df = df.append(temp_df,ignore_index = True)\n",
    "    \n",
    "# rename variables\n",
    "df = df.rename(index=str,columns={'OptType':'CallPut','Spot':'S','Strike':'K','Rate':'rd','DvYd':'q','IVM':'sigma','DyEx':'T','Mid':'Option Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Varaibles: \n",
      "['CallPut' 'S' 'K' 'rd' 'q' 'T']\n",
      "Output Variable\n",
      "Option Price\n"
     ]
    }
   ],
   "source": [
    "# drop Ticker and Volm to make the dataset\n",
    "dataset = df.drop(labels=['Ticker','Volm','sigma'],axis=1)\n",
    "# column names\n",
    "colname = dataset.columns.values\n",
    "print('Input Varaibles: ')\n",
    "print(dataset.columns.values[:-1])\n",
    "print(\"Output Variable\")\n",
    "print(dataset.columns.values[-1])\n",
    "\n",
    "# drop sigma=0\n",
    "#dataset = dataset[dataset['sigma']!=0]\n",
    "# transform T to year\n",
    "dataset['T'] = dataset['T']/365\n",
    "# change rd,q,sigma into percent\n",
    "dataset['rd'] = dataset['rd']/100\n",
    "dataset['q'] = dataset['q']/100\n",
    "#dataset['sigma'] = dataset['sigma']/100\n",
    "\n",
    "# transform dataframe into numpy array and shuffle the data\n",
    "dataset = np.array(dataset)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "X = dataset[:,:-1]\n",
    "Y = dataset[:,-1].reshape(-1,1)\n",
    "\n",
    "# normalize X\n",
    "X = (X-np.mean(X,axis=0))/np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "num_test = int(test_ratio*dataset.shape[0])\n",
    "X_test = X[:num_test]\n",
    "X_train = X[num_test:]\n",
    "Y_test = Y[:num_test]\n",
    "Y_train = Y[num_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,537\n",
      "Trainable params: 17,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9081 samples, validate on 2271 samples\n",
      "Epoch 1/500\n",
      "9081/9081 [==============================] - 0s 37us/step - loss: 734.8297 - val_loss: 755.8523\n",
      "Epoch 2/500\n",
      "9081/9081 [==============================] - 0s 22us/step - loss: 423.1769 - val_loss: 218.4678\n",
      "Epoch 3/500\n",
      "9081/9081 [==============================] - 0s 23us/step - loss: 222.3777 - val_loss: 146.1943\n",
      "Epoch 4/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 105.2602 - val_loss: 164.9172\n",
      "Epoch 5/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 54.7263 - val_loss: 78.1120\n",
      "Epoch 6/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 46.4008 - val_loss: 37.6571\n",
      "Epoch 7/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 70.7611 - val_loss: 177.4135\n",
      "Epoch 8/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 69.7713 - val_loss: 43.0628\n",
      "Epoch 9/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 35.4021 - val_loss: 67.1124\n",
      "Epoch 10/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 26.9207 - val_loss: 33.9096\n",
      "Epoch 11/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 26.6244 - val_loss: 25.7756\n",
      "Epoch 12/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 21.3882 - val_loss: 226.8143\n",
      "Epoch 13/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 28.8409 - val_loss: 27.9261\n",
      "Epoch 14/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 23.5670 - val_loss: 21.9642\n",
      "Epoch 15/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 27.5255 - val_loss: 37.7251\n",
      "Epoch 16/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 21.4218 - val_loss: 19.9657\n",
      "Epoch 17/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 26.1251 - val_loss: 19.9614\n",
      "Epoch 18/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 20.2404 - val_loss: 18.8003\n",
      "Epoch 19/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 17.3397 - val_loss: 19.2420\n",
      "Epoch 20/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 43.4935 - val_loss: 49.8499\n",
      "Epoch 21/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 37.1565 - val_loss: 41.2053\n",
      "Epoch 22/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 47.3596 - val_loss: 39.5774\n",
      "Epoch 23/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 22.8224 - val_loss: 23.8994\n",
      "Epoch 24/500\n",
      "9081/9081 [==============================] - 0s 36us/step - loss: 23.7129 - val_loss: 17.8552\n",
      "Epoch 25/500\n",
      "9081/9081 [==============================] - 0s 35us/step - loss: 19.3910 - val_loss: 49.2242\n",
      "Epoch 26/500\n",
      "9081/9081 [==============================] - 0s 36us/step - loss: 22.3230 - val_loss: 23.3798\n",
      "Epoch 27/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 70.2475 - val_loss: 36.3074\n",
      "Epoch 28/500\n",
      "9081/9081 [==============================] - 0s 35us/step - loss: 43.1946 - val_loss: 19.7520\n",
      "Epoch 29/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 18.9240 - val_loss: 19.5722\n",
      "Epoch 30/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 40.0051 - val_loss: 42.5187\n",
      "Epoch 31/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 198.0477 - val_loss: 72.0125\n",
      "Epoch 32/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 50.6269 - val_loss: 32.0912\n",
      "Epoch 33/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 43.0439 - val_loss: 27.8529\n",
      "Epoch 34/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 38.1246 - val_loss: 23.8280\n",
      "Epoch 35/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 23.2436 - val_loss: 28.2861\n",
      "Epoch 36/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 30.6736 - val_loss: 19.2745\n",
      "Epoch 37/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 22.3094 - val_loss: 44.6320\n",
      "Epoch 38/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 18.0240 - val_loss: 13.9036\n",
      "Epoch 39/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 18.5961 - val_loss: 31.9706\n",
      "Epoch 40/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 19.3824 - val_loss: 19.7164\n",
      "Epoch 41/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 15.7153 - val_loss: 14.5544\n",
      "Epoch 42/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 16.0373 - val_loss: 12.7141\n",
      "Epoch 43/500\n",
      "9081/9081 [==============================] - 0s 36us/step - loss: 14.9681 - val_loss: 12.3288\n",
      "Epoch 44/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 13.4435 - val_loss: 14.5310\n",
      "Epoch 45/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 14.4989 - val_loss: 15.9260\n",
      "Epoch 46/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 20.5962 - val_loss: 14.7320\n",
      "Epoch 47/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 40.4829 - val_loss: 29.4529\n",
      "Epoch 48/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 38.8294 - val_loss: 37.4423\n",
      "Epoch 49/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 23.6148 - val_loss: 30.4673\n",
      "Epoch 50/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 20.5618 - val_loss: 21.7183\n",
      "Epoch 51/500\n",
      "9081/9081 [==============================] - 0s 35us/step - loss: 20.0339 - val_loss: 20.5827\n",
      "Epoch 52/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 24.0805 - val_loss: 18.9507\n",
      "Epoch 53/500\n",
      "9081/9081 [==============================] - 0s 36us/step - loss: 20.4865 - val_loss: 19.3292\n",
      "Epoch 54/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 16.2479 - val_loss: 18.7798\n",
      "Epoch 55/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 17.5055 - val_loss: 22.5665\n",
      "Epoch 56/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 18.1055 - val_loss: 20.5840\n",
      "Epoch 57/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 18.5271 - val_loss: 25.9866\n",
      "Epoch 58/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 16.3580 - val_loss: 21.5258\n",
      "Epoch 59/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 19.6031 - val_loss: 21.3495\n",
      "Epoch 60/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 28.2769 - val_loss: 31.6563\n",
      "Epoch 61/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 32.8104 - val_loss: 24.4883\n",
      "Epoch 62/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 19.3074 - val_loss: 18.5838\n",
      "Epoch 63/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 17.8839 - val_loss: 22.6429\n",
      "Epoch 64/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 23.3429 - val_loss: 17.2241\n",
      "Epoch 65/500\n",
      "9081/9081 [==============================] - 0s 23us/step - loss: 15.2601 - val_loss: 15.2228\n",
      "Epoch 66/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 15.7083 - val_loss: 14.1589\n",
      "Epoch 67/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 15.8810 - val_loss: 14.2390\n",
      "Epoch 68/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 18.5849 - val_loss: 15.3048\n",
      "Epoch 69/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 15.2361 - val_loss: 12.7993\n",
      "Epoch 70/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 13.0554 - val_loss: 29.7764\n",
      "Epoch 71/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 34.6858 - val_loss: 24.8493\n",
      "Epoch 72/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 16.6590 - val_loss: 22.7699\n",
      "Epoch 73/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 18.1330 - val_loss: 17.2481\n",
      "Epoch 74/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 17.3005 - val_loss: 13.8735\n",
      "Epoch 75/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 13.5049 - val_loss: 13.7724\n",
      "Epoch 76/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 13.9909 - val_loss: 13.0232\n",
      "Epoch 77/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 14.5085 - val_loss: 12.9223\n",
      "Epoch 78/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 13.4351 - val_loss: 18.0958\n",
      "Epoch 79/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 12.9484 - val_loss: 15.1838\n",
      "Epoch 80/500\n",
      "9081/9081 [==============================] - 0s 23us/step - loss: 14.5177 - val_loss: 13.9412\n",
      "Epoch 81/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 14.5140 - val_loss: 15.5010\n",
      "Epoch 82/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 13.2313 - val_loss: 10.8662\n",
      "Epoch 83/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 13.1585 - val_loss: 13.0455\n",
      "Epoch 84/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 12.7515 - val_loss: 20.0487\n",
      "Epoch 85/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 13.4257 - val_loss: 12.2664\n",
      "Epoch 86/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 12.5541 - val_loss: 11.3595\n",
      "Epoch 87/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 12.8618 - val_loss: 12.9254\n",
      "Epoch 88/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 13.0443 - val_loss: 14.2208\n",
      "Epoch 89/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 13.5138 - val_loss: 14.1340\n",
      "Epoch 90/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 13.2692 - val_loss: 11.4589\n",
      "Epoch 91/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 15.0454 - val_loss: 15.1100\n",
      "Epoch 92/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.6892 - val_loss: 13.2946\n",
      "Epoch 93/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 13.3264 - val_loss: 10.8562\n",
      "Epoch 94/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 12.5346 - val_loss: 12.1833\n",
      "Epoch 95/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 12.2191 - val_loss: 11.7164\n",
      "Epoch 96/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 11.7350 - val_loss: 10.2475\n",
      "Epoch 97/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.5439 - val_loss: 14.2192\n",
      "Epoch 98/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 12.4273 - val_loss: 10.1409\n",
      "Epoch 99/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.1268 - val_loss: 10.3967\n",
      "Epoch 100/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.3124 - val_loss: 10.5817\n",
      "Epoch 101/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.2707 - val_loss: 11.4287\n",
      "Epoch 102/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.3935 - val_loss: 11.3973\n",
      "Epoch 103/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 12.9484 - val_loss: 17.6504\n",
      "Epoch 104/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 11.9343 - val_loss: 12.1910\n",
      "Epoch 105/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 11.6134 - val_loss: 10.2409\n",
      "Epoch 106/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.2535 - val_loss: 10.7751\n",
      "Epoch 107/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 11.3183 - val_loss: 10.4336\n",
      "Epoch 108/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 11.7102 - val_loss: 11.2731\n",
      "Epoch 109/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 12.9050 - val_loss: 10.2147\n",
      "Epoch 110/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.5182 - val_loss: 10.3192\n",
      "Epoch 111/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.0976 - val_loss: 10.2492\n",
      "Epoch 112/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.9990 - val_loss: 9.9977\n",
      "Epoch 113/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.9710 - val_loss: 10.5008\n",
      "Epoch 114/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.4440 - val_loss: 10.9123\n",
      "Epoch 115/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 15.8378 - val_loss: 10.7324\n",
      "Epoch 116/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 11.3110 - val_loss: 34.7478\n",
      "Epoch 117/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 12.3596 - val_loss: 10.6380\n",
      "Epoch 118/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 11.0007 - val_loss: 10.1719\n",
      "Epoch 119/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.7493 - val_loss: 13.7329\n",
      "Epoch 120/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 11.6114 - val_loss: 11.7972\n",
      "Epoch 121/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.6917 - val_loss: 10.1429\n",
      "Epoch 122/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 11.1989 - val_loss: 9.9028\n",
      "Epoch 123/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.3850 - val_loss: 10.8889\n",
      "Epoch 124/500\n",
      "9081/9081 [==============================] - 0s 35us/step - loss: 11.0698 - val_loss: 10.7181\n",
      "Epoch 125/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.5972 - val_loss: 9.6044\n",
      "Epoch 126/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 11.3583 - val_loss: 11.6699\n",
      "Epoch 127/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.6748 - val_loss: 15.9949\n",
      "Epoch 128/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 11.2075 - val_loss: 9.7872\n",
      "Epoch 129/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 11.1806 - val_loss: 9.7383\n",
      "Epoch 130/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 14.2122 - val_loss: 10.0116\n",
      "Epoch 131/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.8508 - val_loss: 10.7933\n",
      "Epoch 132/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 11.0660 - val_loss: 9.9079\n",
      "Epoch 133/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.8577 - val_loss: 10.9436\n",
      "Epoch 134/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.7711 - val_loss: 10.4144\n",
      "Epoch 135/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.6600 - val_loss: 10.0494\n",
      "Epoch 136/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 11.2049 - val_loss: 10.4120\n",
      "Epoch 137/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.6194 - val_loss: 9.9756\n",
      "Epoch 138/500\n",
      "9081/9081 [==============================] - 0s 34us/step - loss: 11.0768 - val_loss: 9.5864\n",
      "Epoch 139/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.6684 - val_loss: 9.5418\n",
      "Epoch 140/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.9668 - val_loss: 9.4454\n",
      "Epoch 141/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.6845 - val_loss: 9.4421\n",
      "Epoch 142/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.2449 - val_loss: 10.1936\n",
      "Epoch 143/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.5587 - val_loss: 9.9771\n",
      "Epoch 144/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 11.6112 - val_loss: 29.5075\n",
      "Epoch 145/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.7763 - val_loss: 9.6591\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.4404 - val_loss: 10.8672\n",
      "Epoch 147/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 13.7448 - val_loss: 10.0779\n",
      "Epoch 148/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.7247 - val_loss: 9.3991\n",
      "Epoch 149/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.2852 - val_loss: 10.7954\n",
      "Epoch 150/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.6711 - val_loss: 10.2766\n",
      "Epoch 151/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.3532 - val_loss: 9.3925\n",
      "Epoch 152/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.3748 - val_loss: 9.7851\n",
      "Epoch 153/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.7690 - val_loss: 9.6466\n",
      "Epoch 154/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.2552 - val_loss: 9.3431\n",
      "Epoch 155/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 11.0136 - val_loss: 12.2673\n",
      "Epoch 156/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 10.1871 - val_loss: 9.3855\n",
      "Epoch 157/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.2357 - val_loss: 9.6100\n",
      "Epoch 158/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 14.8041 - val_loss: 13.3781\n",
      "Epoch 159/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 11.0413 - val_loss: 9.6240\n",
      "Epoch 160/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.4601 - val_loss: 10.8251\n",
      "Epoch 161/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.4902 - val_loss: 9.6726\n",
      "Epoch 162/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.4739 - val_loss: 10.1147\n",
      "Epoch 163/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.3985 - val_loss: 10.6913\n",
      "Epoch 164/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.6022 - val_loss: 9.3839\n",
      "Epoch 165/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.3699 - val_loss: 11.7291\n",
      "Epoch 166/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.4234 - val_loss: 9.3868\n",
      "Epoch 167/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.1084 - val_loss: 9.4401\n",
      "Epoch 168/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.2637 - val_loss: 11.0542\n",
      "Epoch 169/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 11.3620 - val_loss: 9.6763\n",
      "Epoch 170/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.4109 - val_loss: 9.3076\n",
      "Epoch 171/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.5649 - val_loss: 9.8343\n",
      "Epoch 172/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.4517 - val_loss: 10.6728\n",
      "Epoch 173/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9871 - val_loss: 9.4431\n",
      "Epoch 174/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 10.2142 - val_loss: 9.7584\n",
      "Epoch 175/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.0508 - val_loss: 9.5951\n",
      "Epoch 176/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.9983 - val_loss: 9.4987\n",
      "Epoch 177/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.9967 - val_loss: 9.6548\n",
      "Epoch 178/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.9801 - val_loss: 10.3196\n",
      "Epoch 179/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.1317 - val_loss: 9.8779\n",
      "Epoch 180/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.2012 - val_loss: 10.3027\n",
      "Epoch 181/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.6579 - val_loss: 9.7291\n",
      "Epoch 182/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.1087 - val_loss: 13.3132\n",
      "Epoch 183/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.2443 - val_loss: 9.8989\n",
      "Epoch 184/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 10.3475 - val_loss: 9.3166\n",
      "Epoch 185/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.5138 - val_loss: 9.9898\n",
      "Epoch 186/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 9.9593 - val_loss: 10.1262\n",
      "Epoch 187/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.2342 - val_loss: 13.2919\n",
      "Epoch 188/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.0684 - val_loss: 10.0245\n",
      "Epoch 189/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.8064 - val_loss: 9.1689\n",
      "Epoch 190/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.0923 - val_loss: 10.0258\n",
      "Epoch 191/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.2977 - val_loss: 10.4054\n",
      "Epoch 192/500\n",
      "9081/9081 [==============================] - ETA: 0s - loss: 10.55 - 0s 29us/step - loss: 10.0239 - val_loss: 12.8731\n",
      "Epoch 193/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.0641 - val_loss: 9.3320\n",
      "Epoch 194/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.0647 - val_loss: 10.4034\n",
      "Epoch 195/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9105 - val_loss: 10.8299\n",
      "Epoch 196/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 11.0515 - val_loss: 9.2235\n",
      "Epoch 197/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9134 - val_loss: 10.0119\n",
      "Epoch 198/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.1029 - val_loss: 9.4020\n",
      "Epoch 199/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.2284 - val_loss: 9.2411\n",
      "Epoch 200/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.4106 - val_loss: 9.4798\n",
      "Epoch 201/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 10.0898 - val_loss: 10.7864\n",
      "Epoch 202/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.6380 - val_loss: 9.2918\n",
      "Epoch 203/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8761 - val_loss: 9.3853\n",
      "Epoch 204/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.9964 - val_loss: 9.4074\n",
      "Epoch 205/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 11.3422 - val_loss: 9.2493\n",
      "Epoch 206/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 14.8465 - val_loss: 9.5883\n",
      "Epoch 207/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.5165 - val_loss: 9.7901\n",
      "Epoch 208/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.2613 - val_loss: 9.7945\n",
      "Epoch 209/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.2623 - val_loss: 9.7330\n",
      "Epoch 210/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.0429 - val_loss: 9.4035\n",
      "Epoch 211/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.3584 - val_loss: 10.8962\n",
      "Epoch 212/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.4283 - val_loss: 9.3023\n",
      "Epoch 213/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 10.0594 - val_loss: 9.1624\n",
      "Epoch 214/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.9400 - val_loss: 9.2425\n",
      "Epoch 215/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.5350 - val_loss: 9.1878\n",
      "Epoch 216/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.1746 - val_loss: 9.2010\n",
      "Epoch 217/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 9.9123 - val_loss: 10.7602\n",
      "Epoch 218/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 10.6357 - val_loss: 9.2948\n",
      "Epoch 219/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.1282 - val_loss: 9.3329\n",
      "Epoch 220/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.0200 - val_loss: 9.5136\n",
      "Epoch 221/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 10.0120 - val_loss: 9.3188\n",
      "Epoch 222/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.3829 - val_loss: 9.3138\n",
      "Epoch 223/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.1371 - val_loss: 9.3073\n",
      "Epoch 224/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8344 - val_loss: 10.8346\n",
      "Epoch 225/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 12.1876 - val_loss: 9.3094\n",
      "Epoch 226/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.0659 - val_loss: 9.1400\n",
      "Epoch 227/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9207 - val_loss: 9.9372\n",
      "Epoch 228/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.2677 - val_loss: 9.6764\n",
      "Epoch 229/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.9670 - val_loss: 10.2399\n",
      "Epoch 230/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8655 - val_loss: 9.8369\n",
      "Epoch 231/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6312 - val_loss: 9.2192\n",
      "Epoch 232/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.8346 - val_loss: 9.7287\n",
      "Epoch 233/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.9526 - val_loss: 9.2091\n",
      "Epoch 234/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.0165 - val_loss: 9.0666\n",
      "Epoch 235/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.1356 - val_loss: 9.1271\n",
      "Epoch 236/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.7499 - val_loss: 9.6865\n",
      "Epoch 237/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.8769 - val_loss: 9.9990\n",
      "Epoch 238/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.0344 - val_loss: 10.1468\n",
      "Epoch 239/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.9370 - val_loss: 9.1076\n",
      "Epoch 240/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8889 - val_loss: 9.3291\n",
      "Epoch 241/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.9459 - val_loss: 9.3695\n",
      "Epoch 242/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.7263 - val_loss: 11.2363\n",
      "Epoch 243/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8487 - val_loss: 9.1872\n",
      "Epoch 244/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6298 - val_loss: 9.9339\n",
      "Epoch 245/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.0233 - val_loss: 9.1473\n",
      "Epoch 246/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 14.5759 - val_loss: 10.2791\n",
      "Epoch 247/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.1532 - val_loss: 9.9296\n",
      "Epoch 248/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.5663 - val_loss: 10.0150\n",
      "Epoch 249/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.4889 - val_loss: 9.2559\n",
      "Epoch 250/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.0200 - val_loss: 9.1720\n",
      "Epoch 251/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.8895 - val_loss: 9.2253\n",
      "Epoch 252/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8286 - val_loss: 10.0619\n",
      "Epoch 253/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 9.7871 - val_loss: 13.1389\n",
      "Epoch 254/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8344 - val_loss: 9.3483\n",
      "Epoch 255/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 9.6640 - val_loss: 9.5310\n",
      "Epoch 256/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.2357 - val_loss: 9.1239\n",
      "Epoch 257/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9698 - val_loss: 9.0985\n",
      "Epoch 258/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8244 - val_loss: 9.0860\n",
      "Epoch 259/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6856 - val_loss: 9.1384\n",
      "Epoch 260/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7347 - val_loss: 9.8907\n",
      "Epoch 261/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8947 - val_loss: 9.7308\n",
      "Epoch 262/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9056 - val_loss: 9.9194\n",
      "Epoch 263/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.9846 - val_loss: 9.1701\n",
      "Epoch 264/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9125 - val_loss: 8.9979\n",
      "Epoch 265/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.8221 - val_loss: 9.4022\n",
      "Epoch 266/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 10.0085 - val_loss: 9.2374\n",
      "Epoch 267/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7550 - val_loss: 9.0146\n",
      "Epoch 268/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7515 - val_loss: 9.1953\n",
      "Epoch 269/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.0479 - val_loss: 9.1243\n",
      "Epoch 270/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8159 - val_loss: 11.1341\n",
      "Epoch 271/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.7163 - val_loss: 9.0345\n",
      "Epoch 272/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9979 - val_loss: 9.6135\n",
      "Epoch 273/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5803 - val_loss: 9.4189\n",
      "Epoch 274/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 10.0215 - val_loss: 9.4857\n",
      "Epoch 275/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7384 - val_loss: 10.2674\n",
      "Epoch 276/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8989 - val_loss: 9.9462\n",
      "Epoch 277/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9203 - val_loss: 9.3667\n",
      "Epoch 278/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6236 - val_loss: 10.5626\n",
      "Epoch 279/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6260 - val_loss: 9.2911\n",
      "Epoch 280/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7847 - val_loss: 9.1772\n",
      "Epoch 281/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7120 - val_loss: 9.1573\n",
      "Epoch 282/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6098 - val_loss: 9.0731\n",
      "Epoch 283/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.3525 - val_loss: 10.1053\n",
      "Epoch 284/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6398 - val_loss: 9.1798\n",
      "Epoch 285/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.4189 - val_loss: 9.4117\n",
      "Epoch 286/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7777 - val_loss: 9.0638\n",
      "Epoch 287/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6941 - val_loss: 9.4161\n",
      "Epoch 288/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7824 - val_loss: 9.3128\n",
      "Epoch 289/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 9.5264 - val_loss: 9.5233\n",
      "Epoch 290/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6080 - val_loss: 9.1648\n",
      "Epoch 291/500\n",
      "9081/9081 [==============================] - 0s 36us/step - loss: 10.0476 - val_loss: 9.0966\n",
      "Epoch 292/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6771 - val_loss: 9.0509\n",
      "Epoch 293/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 12.1494 - val_loss: 9.2576\n",
      "Epoch 294/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7449 - val_loss: 9.0994\n",
      "Epoch 295/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6300 - val_loss: 9.1873\n",
      "Epoch 296/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6192 - val_loss: 9.2288\n",
      "Epoch 297/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7259 - val_loss: 9.8791\n",
      "Epoch 298/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7897 - val_loss: 9.4941\n",
      "Epoch 299/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6153 - val_loss: 8.9978\n",
      "Epoch 300/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6656 - val_loss: 8.8959\n",
      "Epoch 301/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.6613 - val_loss: 9.0742\n",
      "Epoch 302/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6939 - val_loss: 9.1760\n",
      "Epoch 303/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.6022 - val_loss: 9.2861\n",
      "Epoch 304/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7121 - val_loss: 9.1823\n",
      "Epoch 305/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7236 - val_loss: 8.9916\n",
      "Epoch 306/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.7038 - val_loss: 9.0308\n",
      "Epoch 307/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8047 - val_loss: 12.7164\n",
      "Epoch 308/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8342 - val_loss: 10.6911\n",
      "Epoch 309/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.8099 - val_loss: 10.3400\n",
      "Epoch 310/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.6564 - val_loss: 9.5524\n",
      "Epoch 311/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6532 - val_loss: 12.0004\n",
      "Epoch 312/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4971 - val_loss: 9.1292\n",
      "Epoch 313/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6176 - val_loss: 9.3209\n",
      "Epoch 314/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4660 - val_loss: 9.0906\n",
      "Epoch 315/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8543 - val_loss: 8.9655\n",
      "Epoch 316/500\n",
      "9081/9081 [==============================] - 0s 33us/step - loss: 9.5831 - val_loss: 9.0730\n",
      "Epoch 317/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5275 - val_loss: 10.4573\n",
      "Epoch 318/500\n",
      "9081/9081 [==============================] - 0s 32us/step - loss: 9.7593 - val_loss: 8.9810\n",
      "Epoch 319/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6965 - val_loss: 9.2490\n",
      "Epoch 320/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5121 - val_loss: 9.2121\n",
      "Epoch 321/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5068 - val_loss: 9.0122\n",
      "Epoch 322/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4519 - val_loss: 9.6019\n",
      "Epoch 323/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.6800 - val_loss: 8.9008\n",
      "Epoch 324/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7169 - val_loss: 9.7527\n",
      "Epoch 325/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6704 - val_loss: 9.3567\n",
      "Epoch 326/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6868 - val_loss: 9.2195\n",
      "Epoch 327/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8153 - val_loss: 9.0274\n",
      "Epoch 328/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5118 - val_loss: 9.1871\n",
      "Epoch 329/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5562 - val_loss: 9.0026\n",
      "Epoch 330/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6944 - val_loss: 9.3469\n",
      "Epoch 331/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9803 - val_loss: 9.9604\n",
      "Epoch 332/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.8920 - val_loss: 8.9584\n",
      "Epoch 333/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6962 - val_loss: 9.1329\n",
      "Epoch 334/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.5060 - val_loss: 9.1039\n",
      "Epoch 335/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4710 - val_loss: 9.8081\n",
      "Epoch 336/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6013 - val_loss: 9.0014\n",
      "Epoch 337/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5432 - val_loss: 8.8588\n",
      "Epoch 338/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5810 - val_loss: 9.7134\n",
      "Epoch 339/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.6998 - val_loss: 9.8632\n",
      "Epoch 340/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6370 - val_loss: 9.5325\n",
      "Epoch 341/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5398 - val_loss: 10.4164\n",
      "Epoch 342/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5487 - val_loss: 9.0756\n",
      "Epoch 343/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8361 - val_loss: 9.7539\n",
      "Epoch 344/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.5451 - val_loss: 9.1836\n",
      "Epoch 345/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4986 - val_loss: 9.3860\n",
      "Epoch 346/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6431 - val_loss: 10.1305\n",
      "Epoch 347/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6303 - val_loss: 9.3371\n",
      "Epoch 348/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4696 - val_loss: 9.0684\n",
      "Epoch 349/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4977 - val_loss: 9.1353\n",
      "Epoch 350/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5974 - val_loss: 9.0129\n",
      "Epoch 351/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4795 - val_loss: 9.0988\n",
      "Epoch 352/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.8582 - val_loss: 9.3766\n",
      "Epoch 353/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6257 - val_loss: 9.2552\n",
      "Epoch 354/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5085 - val_loss: 9.1378\n",
      "Epoch 355/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5950 - val_loss: 9.5180\n",
      "Epoch 356/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9065 - val_loss: 9.1883\n",
      "Epoch 357/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6757 - val_loss: 9.0821\n",
      "Epoch 358/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6348 - val_loss: 9.1708\n",
      "Epoch 359/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7079 - val_loss: 9.1983\n",
      "Epoch 360/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6361 - val_loss: 8.9978\n",
      "Epoch 361/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.4292 - val_loss: 9.6480\n",
      "Epoch 362/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6862 - val_loss: 9.4452\n",
      "Epoch 363/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4191 - val_loss: 9.2614\n",
      "Epoch 364/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.9399 - val_loss: 11.2400\n",
      "Epoch 365/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6476 - val_loss: 8.9733\n",
      "Epoch 366/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6899 - val_loss: 9.3041\n",
      "Epoch 367/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8139 - val_loss: 9.1608\n",
      "Epoch 368/500\n",
      "9081/9081 [==============================] - ETA: 0s - loss: 8.429 - 0s 29us/step - loss: 9.5247 - val_loss: 9.9600\n",
      "Epoch 369/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5588 - val_loss: 9.1458\n",
      "Epoch 370/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.4516 - val_loss: 8.9777\n",
      "Epoch 371/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8617 - val_loss: 9.2002\n",
      "Epoch 372/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4331 - val_loss: 9.2774\n",
      "Epoch 373/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 11.7126 - val_loss: 9.5890\n",
      "Epoch 374/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5564 - val_loss: 8.9825\n",
      "Epoch 375/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5300 - val_loss: 8.9275\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.4383 - val_loss: 9.9822\n",
      "Epoch 377/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4179 - val_loss: 9.3855\n",
      "Epoch 378/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.8092 - val_loss: 9.1714\n",
      "Epoch 379/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4105 - val_loss: 11.6911\n",
      "Epoch 380/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5390 - val_loss: 9.0897\n",
      "Epoch 381/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8315 - val_loss: 10.1982\n",
      "Epoch 382/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7642 - val_loss: 9.3238\n",
      "Epoch 383/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 10.0273 - val_loss: 16.9226\n",
      "Epoch 384/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6620 - val_loss: 10.4109\n",
      "Epoch 385/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.7268 - val_loss: 10.1425\n",
      "Epoch 386/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.5013 - val_loss: 9.0636\n",
      "Epoch 387/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.4577 - val_loss: 8.9689\n",
      "Epoch 388/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 10.4913 - val_loss: 9.1227\n",
      "Epoch 389/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.5916 - val_loss: 9.5279\n",
      "Epoch 390/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.6275 - val_loss: 9.3353\n",
      "Epoch 391/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4401 - val_loss: 9.4735\n",
      "Epoch 392/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4441 - val_loss: 8.9662\n",
      "Epoch 393/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.4237 - val_loss: 9.0877\n",
      "Epoch 394/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5699 - val_loss: 9.2226\n",
      "Epoch 395/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5456 - val_loss: 9.0519\n",
      "Epoch 396/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5242 - val_loss: 9.1619\n",
      "Epoch 397/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4617 - val_loss: 8.9270\n",
      "Epoch 398/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.7046 - val_loss: 9.0353\n",
      "Epoch 399/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6312 - val_loss: 9.2576\n",
      "Epoch 400/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5220 - val_loss: 9.6981\n",
      "Epoch 401/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.4767 - val_loss: 9.8583\n",
      "Epoch 402/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.1910 - val_loss: 9.4638\n",
      "Epoch 403/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.5157 - val_loss: 8.8733\n",
      "Epoch 404/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4879 - val_loss: 9.0730\n",
      "Epoch 405/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5286 - val_loss: 9.0523\n",
      "Epoch 406/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4049 - val_loss: 8.9050\n",
      "Epoch 407/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.4424 - val_loss: 9.1638\n",
      "Epoch 408/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7380 - val_loss: 9.7221\n",
      "Epoch 409/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.6111 - val_loss: 9.5990\n",
      "Epoch 410/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7243 - val_loss: 8.9504\n",
      "Epoch 411/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.4241 - val_loss: 9.0992\n",
      "Epoch 412/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.8225 - val_loss: 9.0348\n",
      "Epoch 413/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4211 - val_loss: 10.3614\n",
      "Epoch 414/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.6333 - val_loss: 8.9395\n",
      "Epoch 415/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6729 - val_loss: 12.0792\n",
      "Epoch 416/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7530 - val_loss: 8.9271\n",
      "Epoch 417/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5310 - val_loss: 8.9615\n",
      "Epoch 418/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7516 - val_loss: 9.1767\n",
      "Epoch 419/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4568 - val_loss: 9.2740\n",
      "Epoch 420/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6176 - val_loss: 11.7381\n",
      "Epoch 421/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6185 - val_loss: 9.3880\n",
      "Epoch 422/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4555 - val_loss: 8.9069\n",
      "Epoch 423/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.0744 - val_loss: 9.0636\n",
      "Epoch 424/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4941 - val_loss: 8.9606\n",
      "Epoch 425/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4889 - val_loss: 9.6025\n",
      "Epoch 426/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5055 - val_loss: 9.1735\n",
      "Epoch 427/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5019 - val_loss: 10.2078\n",
      "Epoch 428/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.8025 - val_loss: 9.5162\n",
      "Epoch 429/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.7680 - val_loss: 9.7401\n",
      "Epoch 430/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 10.1199 - val_loss: 9.4227\n",
      "Epoch 431/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4946 - val_loss: 9.2500\n",
      "Epoch 432/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4505 - val_loss: 9.0328\n",
      "Epoch 433/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5455 - val_loss: 8.9585\n",
      "Epoch 434/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.6309 - val_loss: 8.9203\n",
      "Epoch 435/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5231 - val_loss: 9.2876\n",
      "Epoch 436/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5073 - val_loss: 9.6883\n",
      "Epoch 437/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4468 - val_loss: 9.5649\n",
      "Epoch 438/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5043 - val_loss: 9.2253\n",
      "Epoch 439/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5507 - val_loss: 9.6347\n",
      "Epoch 440/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5336 - val_loss: 9.5620\n",
      "Epoch 441/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4978 - val_loss: 8.9009\n",
      "Epoch 442/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3874 - val_loss: 9.6662\n",
      "Epoch 443/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.7560 - val_loss: 9.1036\n",
      "Epoch 444/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.6226 - val_loss: 9.2653\n",
      "Epoch 445/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.9239 - val_loss: 8.9913\n",
      "Epoch 446/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5103 - val_loss: 9.8482\n",
      "Epoch 447/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4708 - val_loss: 9.3839\n",
      "Epoch 448/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.3737 - val_loss: 8.9383\n",
      "Epoch 449/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4308 - val_loss: 9.3742\n",
      "Epoch 450/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5022 - val_loss: 9.0749\n",
      "Epoch 451/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5993 - val_loss: 8.9758\n",
      "Epoch 452/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.3779 - val_loss: 9.3875\n",
      "Epoch 453/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.3501 - val_loss: 9.1222\n",
      "Epoch 454/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.7684 - val_loss: 10.3375\n",
      "Epoch 455/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3986 - val_loss: 9.0744\n",
      "Epoch 456/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3703 - val_loss: 9.8448\n",
      "Epoch 457/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4378 - val_loss: 10.5611\n",
      "Epoch 458/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5202 - val_loss: 9.3799\n",
      "Epoch 459/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3263 - val_loss: 8.8626\n",
      "Epoch 460/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5188 - val_loss: 10.5357\n",
      "Epoch 461/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7405 - val_loss: 9.8165\n",
      "Epoch 462/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.5069 - val_loss: 9.1079\n",
      "Epoch 463/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5860 - val_loss: 26.1100\n",
      "Epoch 464/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.6706 - val_loss: 9.2898\n",
      "Epoch 465/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5664 - val_loss: 11.6717\n",
      "Epoch 466/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.4487 - val_loss: 9.0930\n",
      "Epoch 467/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4792 - val_loss: 9.7371\n",
      "Epoch 468/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4943 - val_loss: 9.3466\n",
      "Epoch 469/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 10.0726 - val_loss: 9.6015\n",
      "Epoch 470/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4229 - val_loss: 8.8449\n",
      "Epoch 471/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4808 - val_loss: 8.9265\n",
      "Epoch 472/500\n",
      "9081/9081 [==============================] - 0s 25us/step - loss: 9.4560 - val_loss: 8.9444\n",
      "Epoch 473/500\n",
      "9081/9081 [==============================] - 0s 24us/step - loss: 9.4633 - val_loss: 8.9241\n",
      "Epoch 474/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.5345 - val_loss: 9.7381\n",
      "Epoch 475/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.3794 - val_loss: 9.5314\n",
      "Epoch 476/500\n",
      "9081/9081 [==============================] - 0s 27us/step - loss: 9.3181 - val_loss: 9.5945\n",
      "Epoch 477/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4208 - val_loss: 8.9668\n",
      "Epoch 478/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4036 - val_loss: 8.9963\n",
      "Epoch 479/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.9821 - val_loss: 9.2626\n",
      "Epoch 480/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.3749 - val_loss: 9.2515\n",
      "Epoch 481/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.4902 - val_loss: 9.7806\n",
      "Epoch 482/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5085 - val_loss: 9.2305\n",
      "Epoch 483/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.7480 - val_loss: 9.2794\n",
      "Epoch 484/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 15.1765 - val_loss: 18.8358\n",
      "Epoch 485/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7386 - val_loss: 9.1085\n",
      "Epoch 486/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5120 - val_loss: 12.1788\n",
      "Epoch 487/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5305 - val_loss: 12.5057\n",
      "Epoch 488/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.7916 - val_loss: 9.0321\n",
      "Epoch 489/500\n",
      "9081/9081 [==============================] - 0s 26us/step - loss: 9.4204 - val_loss: 8.9789\n",
      "Epoch 490/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.5101 - val_loss: 9.2444\n",
      "Epoch 491/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.4293 - val_loss: 9.8215\n",
      "Epoch 492/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.4754 - val_loss: 9.0761\n",
      "Epoch 493/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.4508 - val_loss: 8.9097\n",
      "Epoch 494/500\n",
      "9081/9081 [==============================] - 0s 31us/step - loss: 9.5645 - val_loss: 8.9629\n",
      "Epoch 495/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3447 - val_loss: 9.0037\n",
      "Epoch 496/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.5183 - val_loss: 8.8870\n",
      "Epoch 497/500\n",
      "9081/9081 [==============================] - 0s 28us/step - loss: 9.3743 - val_loss: 9.0543\n",
      "Epoch 498/500\n",
      "9081/9081 [==============================] - 0s 30us/step - loss: 9.3114 - val_loss: 8.9834\n",
      "Epoch 499/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.9414 - val_loss: 9.3139\n",
      "Epoch 500/500\n",
      "9081/9081 [==============================] - 0s 29us/step - loss: 9.5675 - val_loss: 9.3766\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(BatchNormalization(input_shape=[7]))\n",
    "model.add(Dense(128, input_shape = [6], activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1, activation ='relu'))\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(x=X_train,y=Y_train, epochs=500, batch_size=64, validation_split=0.2, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and cross validation mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e9b7991cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838/2838 [==============================] - 0s 16us/step\n",
      "8.429300742702974\n"
     ]
    }
   ],
   "source": [
    "loss=model.evaluate(x=X_test,y=Y_test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e9b7bd50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_test,predicted,'o')\n",
    "plt.plot(Y_test,f(Y_test),'r-')\n",
    "plt.title('Real market price VS. Model predicted price')\n",
    "plt.xlabel('Real market price')\n",
    "plt.ylabel('Model predicted price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 matches\n",
      "\n",
      "Real Market Price is: [43.72499847]\n",
      "Model Predicted Price is: [43.724792]\n",
      "\n",
      "Real Market Price is: [2.47000003]\n",
      "Model Predicted Price is: [2.4702091]\n",
      "\n",
      "Real Market Price is: [24.95000076]\n",
      "Model Predicted Price is: [24.949577]\n",
      "\n",
      "Real Market Price is: [50.47499847]\n",
      "Model Predicted Price is: [50.47622]\n",
      "\n",
      "Real Market Price is: [15.125]\n",
      "Model Predicted Price is: [15.127515]\n",
      "\n",
      "Real Market Price is: [106.67500305]\n",
      "Model Predicted Price is: [106.677956]\n",
      "\n",
      "Real Market Price is: [122.69999695]\n",
      "Model Predicted Price is: [122.696945]\n",
      "\n",
      "Real Market Price is: [2.59500003]\n",
      "Model Predicted Price is: [2.5983906]\n",
      "\n",
      "Real Market Price is: [17.27499962]\n",
      "Model Predicted Price is: [17.278416]\n",
      "\n",
      "Real Market Price is: [50.57500076]\n",
      "Model Predicted Price is: [50.579277]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff = {}\n",
    "for i,pred in enumerate(predicted):\n",
    "    diff[i]=abs(pred-Y_test[i])\n",
    "diff = zip(diff.values(),diff.keys())\n",
    "top10 = sorted(diff)[:10]\n",
    "print(\"Top 10 matches\\n\")\n",
    "for item in top10:\n",
    "    ind = item[1]\n",
    "    print(\"Real Market Price is: {}\".format(Y_test[ind]))\n",
    "    print(\"Model Predicted Price is: {}\\n\".format(predicted[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 matches\n",
      "\n",
      "Real Market Price is: [90.375]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [70.65000153]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [45.375]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [40.375]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [30.5]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [25.375]\n",
      "Model Predicted Price is: [0.]\n",
      "\n",
      "Real Market Price is: [52.40000153]\n",
      "Model Predicted Price is: [30.574669]\n",
      "\n",
      "Real Market Price is: [21.70000076]\n",
      "Model Predicted Price is: [5.289818]\n",
      "\n",
      "Real Market Price is: [47.09999847]\n",
      "Model Predicted Price is: [31.670918]\n",
      "\n",
      "Real Market Price is: [41.875]\n",
      "Model Predicted Price is: [27.015781]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff = {}\n",
    "for i,pred in enumerate(predicted):\n",
    "    diff[i]=abs(pred-Y_test[i])\n",
    "diff = zip(diff.values(),diff.keys())\n",
    "worst10 = sorted(diff,reverse=True)[:10]\n",
    "print(\"Worst 10 matches\\n\")\n",
    "for item in worst10:\n",
    "    ind = item[1]\n",
    "    print(\"Real Market Price is: {}\".format(Y_test[ind]))\n",
    "    print(\"Model Predicted Price is: {}\\n\".format(predicted[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
